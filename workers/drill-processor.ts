/**
 * Drill ç”Ÿæˆå¤„ç†å™¨ (V2.0 Schedule-Driven)
 */
import { Job } from 'bullmq';
import { db } from '@/lib/db';
import { redis } from '@/lib/queue/connection';
import { Prisma } from '@prisma/client';
import { DrillJobData } from '@/lib/queue/inventory-queue';
import { Vocab } from '@prisma/client';
import { generateWithFailover } from './llm-failover';
// import { getDrillBatchPrompt } from '@/lib/prompts/drill'; // Legacy removed
import { inventory } from '@/lib/inventory';
import { logger } from '@/lib/logger';
import { z } from 'zod';
import crypto from 'crypto';
import { SessionMode, BriefingPayload } from '@/types/briefing';
import { safeParse } from '@/lib/ai/utils';
import { ContextSelector } from '@/lib/ai/context-selector';
import { validateL0Payload, createPivotPayload, L0Mode } from '@/lib/validations/l0-schemas';

const log = logger.child({ module: 'drill-processor' });

// --- Pivot é…ç½® (Retry é€»è¾‘å¾…åç»­å®ç°) ---
const PIVOT_CONFIG = {
    enabled: true, // å¯ç”¨ Pivot å…œåº•
};

// AI è¾“å‡º Schema (Reusable)
const SingleDrillSchema = z.object({
    meta: z.object({
        format: z.enum(['chat', 'email', 'memo']),
        // mode: z.enum(['SYNTAX', 'CHUNKING', 'NUANCE', 'BLITZ']), // Optional in LLM response, inferred from context
        target_word: z.string().optional(),
    }),
    segments: z.array(z.any()),
});

const BatchDrillOutputSchema = z.object({
    drills: z.array(SingleDrillSchema),
});

/**
 * å¤„ç† Drill ç”Ÿæˆ Job
 */
export async function processDrillJob(job: Job<DrillJobData>) {
    const { userId, mode, correlationId, vocabId, vocabIds } = job.data;

    log.info({
        correlationId,
        userId,
        mode,
        jobName: job.name,
        vocabIds: vocabIds?.length
    }, 'ğŸ”„ [Worker] æ”¶åˆ°ä»»åŠ¡ (Job Received)');

    try {
        // ============================================
        // 1. ç¡®å®šç”Ÿæˆç›®æ ‡ (Candidates)
        // ============================================
        let candidates: DrillCandidate[] = [];

        if (vocabIds && vocabIds.length > 0) {
            // Plan C: Batch Replenishment
            log.info({ count: vocabIds.length }, 'ğŸ‘‰ ç­–ç•¥: Plan C (Batch IDs)');
            candidates = await fetchSpecificCandidates(userId, vocabIds);
        } else if (vocabId) {
            // Plan B: Single Emergency Replenishment
            log.info({ vocabId }, 'ğŸ‘‰ ç­–ç•¥: Plan B (Single ID)');
            candidates = await fetchSpecificCandidates(userId, [Number(vocabId)]);
        } else {
            // [Fix] V2 Generic Fetch (Schedule-Driven)
            if (job.name.startsWith('generate-')) {
                log.info({ mode }, 'ğŸ‘‰ ç­–ç•¥: V2 Generic Fetch (Scheduled)');
                const limit = job.data.forceLimit || 10;
                candidates = await fetchDueCandidates(userId, mode, limit);
            } else {
                log.warn({ jobName: job.name }, 'âŒ æœªçŸ¥ä»»åŠ¡ç±»å‹ï¼Œè·³è¿‡');
                return { success: false, reason: 'legacy_not_supported_v2' };
            }
        }

        if (candidates.length === 0) {
            log.warn({ correlationId }, 'âš ï¸ æ— å¯ç”¨å€™é€‰è¯ (Candidates Empty)');
            return { success: false, reason: 'no_candidates' };
        }

        log.info({ count: candidates.length }, 'âœ… é”å®šå€™é€‰è¯ (Candidates Locked)');

        // ============================================
        // 2. æ™ºèƒ½è·¯ç”± & åˆ†ç»„ç”Ÿæˆ (Smart Dispatch)
        // ============================================

        const syntaxGroup: DrillCandidate[] = [];
        const blitzGroup: DrillCandidate[] = [];
        const phraseGroup: DrillCandidate[] = []; // Reserved for AUDIO mappings if needed

        // Routing Logic
        if (mode === 'SYNTAX') {
            for (const c of candidates) {
                // FSRS Rule: 
                // Stage 1 (New) -> Syntax (S-V-O)
                // Stage 2 (Review < 7d) -> Syntax (POS Trap)
                // Stage 3 (Review >= 7d) -> Blitz (Collocations / Visual Trap)

                const isReview = c.type === 'REVIEW';
                const stability = c.reviewData?.stability || 0;

                if (!isReview || stability < 7) {
                    syntaxGroup.push(c);
                } else {
                    blitzGroup.push(c);
                }
            }
            log.info({
                total: candidates.length,
                syntaxParams: syntaxGroup.length,
                blitzParams: blitzGroup.length
            }, 'ğŸ”€ [Smart Dispatch] Grouped candidates based on FSRS');
        } else {
            // Fallback / Other Modes
            if (mode === 'BLITZ') {
                blitzGroup.push(...candidates);
            } else if (mode === 'PHRASE' || mode === 'AUDIO') {
                phraseGroup.push(...candidates);
            } else {
                // Default fallback to Syntax
                syntaxGroup.push(...candidates);
            }
        }

        // ============================================
        // 3. æ‰§è¡Œç”Ÿæˆ (Parallel Execution)
        // ============================================

        const generatedDrills: any[] = [];
        let primaryProvider = 'unknown';

        const tasks: Promise<void>[] = [];

        // --- Task A: Process Syntax Group ---
        if (syntaxGroup.length > 0) {
            tasks.push((async () => {
                const { getL0SyntaxBatchPrompt } = await import('@/lib/generators/l0/syntax');
                const inputs = await Promise.all(syntaxGroup.map(c => mapToSyntaxInput(userId, c)));
                const p = getL0SyntaxBatchPrompt(inputs);

                const { text, provider } = await generateWithFailover(p.system, p.user);
                primaryProvider = provider;

                const result = safeParse(text, BatchDrillOutputSchema, {
                    model: provider,
                    systemPrompt: p.system,
                    userPrompt: p.user
                });

                // Map results back to candidates 
                // Assumes LLM respects order. Drill output is array.
                result.drills.forEach((drill, idx) => {
                    // Safety check index
                    if (idx < syntaxGroup.length) {
                        generatedDrills.push({
                            drill,
                            candidate: syntaxGroup[idx],
                            systemPrompt: p.system,
                            userPrompt: p.user,
                            provider: provider
                        });
                    }
                });
            })().catch(err => log.error({ error: err.message }, 'Failed to process Syntax group')));
        }

        // --- Task B: Process Blitz Group ---
        if (blitzGroup.length > 0) {
            tasks.push((async () => {
                const { getL0BlitzBatchPrompt } = await import('@/lib/generators/l0/blitz');
                const inputs = blitzGroup.map(c => {
                    let collys: string[] = [];
                    if (Array.isArray(c.collocations)) {
                        collys = c.collocations.map((item: any) => typeof item === 'string' ? item : item.text).filter(Boolean);
                    }
                    return {
                        targetWord: c.word,
                        meaning: c.definition_cn || '',
                        collocations: collys
                    };
                });
                const p = getL0BlitzBatchPrompt(inputs);

                const { text, provider } = await generateWithFailover(p.system, p.user);

                const result = safeParse(text, BatchDrillOutputSchema, {
                    model: provider,
                    systemPrompt: p.system,
                    userPrompt: p.user
                });

                result.drills.forEach((drill, idx) => {
                    if (idx < blitzGroup.length) {
                        generatedDrills.push({
                            drill,
                            candidate: blitzGroup[idx],
                            systemPrompt: p.system,
                            userPrompt: p.user,
                            provider: provider
                        });
                    }
                });
            })().catch(err => log.error({ error: err.message }, 'Failed to process Blitz group')));
        }

        // --- Task C: Process Phrase Group (if any) ---
        if (phraseGroup.length > 0) {
            tasks.push((async () => {
                const { getL0PhraseBatchPrompt } = await import('@/lib/generators/l0/phrase');
                const inputs = await Promise.all(phraseGroup.map(async c => {
                    const modifiers = await getContextWords(userId, c.vocabId, c.word);
                    return {
                        targetWord: c.word,
                        meaning: c.definition_cn || 'æš‚æ— é‡Šä¹‰',
                        modifiers: modifiers.length > 0 ? modifiers : ['frequently', 'highly', 'effectively']
                    };
                }));
                const p = getL0PhraseBatchPrompt(inputs);

                const { text, provider } = await generateWithFailover(p.system, p.user);

                const result = safeParse(text, BatchDrillOutputSchema, {
                    model: provider,
                    systemPrompt: p.system,
                    userPrompt: p.user
                });

                result.drills.forEach((drill, idx) => {
                    if (idx < phraseGroup.length) {
                        generatedDrills.push({
                            drill,
                            candidate: phraseGroup[idx],
                            systemPrompt: p.system,
                            userPrompt: p.user,
                            provider: provider
                        });
                    }
                });
            })().catch(err => log.error({ error: err.message }, 'Failed to process Phrase group')));
        }

        await Promise.all(tasks);

        log.info({ generatedCount: generatedDrills.length }, 'âœ… LLM ç”Ÿæˆå®Œæˆ (All Groups)');

        // ============================================
        // 4. ä¿å­˜åˆ° V2 Inventory (Redis) + L0 Schema éªŒè¯
        // ============================================
        let successCount = 0;
        let pivotCount = 0;

        for (const item of generatedDrills) {
            const { drill: rawDrill, candidate } = item;

            // æ„å»ºåˆå§‹ Payload
            let payload: BriefingPayload = {
                meta: {
                    format: rawDrill.meta.format as any,
                    mode: mode,
                    batch_size: 1, // Stored individually
                    sys_prompt_version: 'v2.8-schedule',
                    vocabId: candidate.vocabId,
                    target_word: candidate.word,
                    source: 'llm_v2'
                },
                segments: rawDrill.segments,
            };

            // --- L0 Schema éªŒè¯ (Phase 1: Defense Layer) ---
            const isL0Mode = ['SYNTAX', 'PHRASE', 'BLITZ'].includes(mode);

            if (isL0Mode) {
                const validation = validateL0Payload(mode as L0Mode, payload);

                if (!validation.success) {
                    log.warn({
                        vocabId: candidate.vocabId,
                        word: candidate.word,
                        mode,
                        error: validation.error,
                        rawPayload: JSON.stringify(validation.rawPayload).slice(0, 500), // æˆªæ–­æ—¥å¿—
                    }, 'âš ï¸ L0 Schema éªŒè¯å¤±è´¥');

                    // Pivot å…œåº•: ä½¿ç”¨å®‰å…¨ Payload
                    if (PIVOT_CONFIG.enabled) {
                        payload = createPivotPayload(
                            mode as L0Mode,
                            candidate.vocabId,
                            candidate.word,
                            'Generation failed, please retry.'
                        );
                        pivotCount++;
                        log.info({ vocabId: candidate.vocabId, word: candidate.word }, 'ğŸ”„ ä½¿ç”¨ Pivot å…œåº• Payload');
                    } else {
                        // ä¸ä½¿ç”¨ Pivot æ—¶è·³è¿‡æ­¤æ¡ç›®
                        log.warn({ vocabId: candidate.vocabId }, 'âŒ è·³è¿‡æ— æ•ˆ Payload (Pivot å·²ç¦ç”¨)');
                        continue;
                    }
                }
            }

            await inventory.pushDrill(userId, mode, candidate.vocabId, payload);
            successCount++;

            // [Phase 5] Real-time Stream Publish & Persist
            // Fire and forget - do not block main flow
            const streamEvent = JSON.stringify({
                id: `GEN-${crypto.randomUUID().split('-')[0]}`, // Short unique ID
                timestamp: new Date().toISOString(),
                payload: payload,
                status: 'success',
                debug: {
                    systemPrompt: item.systemPrompt,
                    userPrompt: item.userPrompt,
                    model: item.provider
                }
            });

            Promise.all([
                redis.publish('admin:drill-stream', streamEvent),
                redis.lpush('admin:drill-history', streamEvent),
                redis.ltrim('admin:drill-history', 0, 99) // Keep last 100
            ]).catch(err => log.error({ err }, 'Failed to publish/persist stream event'));
        }

        if (pivotCount > 0) {
            log.warn({ correlationId, pivotCount, successCount }, 'âš ï¸ éƒ¨åˆ† Drill ä½¿ç”¨äº† Pivot å…œåº•');
        }

        log.info({ correlationId, successCount }, 'Drill V2 å…¥åº“å®Œæˆ');

        return { success: true, count: successCount, pivotCount, provider: primaryProvider };

    } catch (error) {
        log.error({ correlationId, error: (error as Error).message }, 'Drill ç”Ÿæˆå¤±è´¥');
        throw error;
    }
}

// --- Helpers ---

interface DrillCandidate {
    vocabId: number;
    word: string;
    definition_cn: string | null;
    word_family: any;
    collocations?: any;
    type?: 'NEW' | 'REVIEW'; // [Smart Dispatch] Added
    reviewData?: any;        // [Smart Dispatch] Added
}

async function fetchSpecificCandidates(userId: string, vocabIds: number[]): Promise<DrillCandidate[]> {
    const vocabs = await db.vocab.findMany({
        where: { id: { in: vocabIds } }
    });
    return vocabs.map(mapToCandidate);
}

function mapToCandidate(v: Vocab): DrillCandidate {
    return {
        vocabId: v.id,
        word: v.word,
        definition_cn: v.definition_cn,
        word_family: v.word_family,
        collocations: v.collocations,
        type: 'NEW', // Default for manual fetch
        reviewData: null
    };
}

/**
 * è·å–ä¸Šä¸‹æ–‡å•è¯ (The "N" in "1+N")
 * ç­–ç•¥ (Hybrid):
 * 1. å°è¯•ä» UserProgress (Learning/Review) ä¸­æ‰¾è¯­ä¹‰ç›¸å…³çš„ (Vector Search)
 * 2. å¦‚æœä¸è¶³ 3 ä¸ªï¼Œä» Global Vocab ä¸­æ‰¾è¯­ä¹‰ç›¸å…³çš„ (Vector Search)
 * 3. å…œåº•ï¼šéšæœºé€‰æ‹©
 */
async function getContextWords(userId: string, targetVocabId: number, targetWord: string): Promise<string[]> {
    try {
        const selectorResult = await ContextSelector.select(userId, targetVocabId, {
            count: 3,
            strategies: ['USER_VECTOR', 'GLOBAL_VECTOR', 'RANDOM'],
            minDistance: 0.15,
            maxDistance: 0.5,
            excludeIds: [targetVocabId]
        });

        return selectorResult.map(v => v.word);
    } catch (e) {
        log.error({ error: String(e), targetWord }, 'ContextSelector failed, returning empty');
        return [];
    }
}

/**
 * è·å–éœ€è¦é¢„ç”Ÿæˆçš„å€™é€‰è¯
 * [é‡æ„] ç°åœ¨ç›´æ¥ä½¿ç”¨ OMPS é€‰è¯é€»è¾‘ï¼Œç¡®ä¿ç”Ÿäº§å’Œæ¶ˆè´¹ä½¿ç”¨ç›¸åŒçš„ç­–ç•¥
 */
async function fetchDueCandidates(userId: string, mode: SessionMode, limit: number): Promise<DrillCandidate[]> {
    // å¯¼å…¥ OMPS é€‰è¯å¼•æ“
    const { fetchOMPSCandidates } = await import('@/lib/services/omps-core');

    // é…ç½®è¯æ€§è¿‡æ»¤ï¼ˆä¸ get-next-drill.ts ä¿æŒä¸€è‡´ï¼‰
    let posFilter: string[] | undefined;
    if (mode === 'SYNTAX') {
        posFilter = ['v', 'n', 'v.', 'n.', 'vi', 'vt', 'vi.', 'vt.', 'noun', 'verb', 'åè©', 'å‹•è©'];
    }

    // 1. ä½¿ç”¨ OMPS è·å–å€™é€‰è¯ï¼ˆä¸æ¶ˆè´¹ä¾§é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
    const bufferLimit = limit * 2; // è·å–2å€æ•°é‡ï¼Œç”¨äºè¿‡æ»¤
    const ompsCandidates = await fetchOMPSCandidates(
        userId,
        bufferLimit,
        { posFilter },
        [], // excludeIds
        mode // [Fix] Pass mode to determine track
    );

    if (ompsCandidates.length === 0) {
        return [];
    }

    // 2. è¿‡æ»¤å‡ºåº“å­˜ä¸è¶³çš„å•è¯ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
    const vocabIds = ompsCandidates.map(c => c.vocabId);
    const inventoryCounts = await inventory.getInventoryCounts(userId, mode, vocabIds);

    const needsGeneration = ompsCandidates.filter(c => {
        const count = inventoryCounts[c.vocabId] || 0;
        return count < 2; // åº“å­˜ < 2 æ‰éœ€è¦ç”Ÿæˆ
    });

    if (needsGeneration.length < ompsCandidates.length) {
        log.info(
            { userId, mode, skipped: ompsCandidates.length - needsGeneration.length },
            'âœ… è·³è¿‡å·²æœ‰åº“å­˜çš„å•è¯'
        );
    }

    // 3. è½¬æ¢ä¸º DrillCandidate æ ¼å¼
    const candidates = needsGeneration.map(omps => ({
        vocabId: omps.vocabId,
        word: omps.word,
        definition_cn: omps.definition_cn,
        word_family: omps.word_family,
        collocations: omps.collocations,
        type: omps.type, // [Smart Dispatch] Pass type
        reviewData: omps.reviewData // [Smart Dispatch] Pass FSRS data
    }));

    // 4. è¿”å›æŒ‡å®šæ•°é‡
    return candidates.slice(0, limit);
}

// --- Helper: Input Mappers ---

async function mapToSyntaxInput(userId: string, c: DrillCandidate) {
    const contextWords = await getContextWords(userId, c.vocabId, c.word);
    return {
        targetWord: c.word,
        meaning: c.definition_cn || 'æš‚æ— é‡Šä¹‰',
        contextWords,
        wordFamily: (c.word_family as Record<string, string>) || { v: c.word },
    };
}
