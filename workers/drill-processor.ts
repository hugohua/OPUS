/**
 * Drill ç”Ÿæˆå¤„ç†å™¨ (V2.0 Schedule-Driven)
 */
import { Job } from 'bullmq';
import { db } from '@/lib/db';
import { Prisma } from '@prisma/client';
import { DrillJobData } from '@/lib/queue/inventory-queue';
import { Vocab } from '@prisma/client';
import { generateWithFailover } from './llm-failover';
// import { getDrillBatchPrompt } from '@/lib/prompts/drill'; // Legacy removed
import { inventory } from '@/lib/inventory';
import { logger } from '@/lib/logger';
import { z } from 'zod';
import { SessionMode, BriefingPayload } from '@/types/briefing';
import { safeParse } from '@/lib/ai/utils';
import { ContextSelector } from '@/lib/ai/context-selector';

const log = logger.child({ module: 'drill-processor' });

// AI è¾“å‡º Schema (Reusable)
const SingleDrillSchema = z.object({
    meta: z.object({
        format: z.enum(['chat', 'email', 'memo']),
        // mode: z.enum(['SYNTAX', 'CHUNKING', 'NUANCE', 'BLITZ']), // Optional in LLM response, inferred from context
        target_word: z.string().optional(),
    }),
    segments: z.array(z.any()),
});

const BatchDrillOutputSchema = z.object({
    drills: z.array(SingleDrillSchema),
});

/**
 * å¤„ç† Drill ç”Ÿæˆ Job
 */
export async function processDrillJob(job: Job<DrillJobData>) {
    const { userId, mode, correlationId, vocabId, vocabIds } = job.data;

    log.info({
        correlationId,
        userId,
        mode,
        jobName: job.name,
        vocabIds: vocabIds?.length
    }, 'ğŸ”„ [Worker] æ”¶åˆ°ä»»åŠ¡ (Job Received)');

    try {
        // ============================================
        // 1. ç¡®å®šç”Ÿæˆç›®æ ‡ (Candidates)
        // ============================================
        let candidates: DrillCandidate[] = [];

        if (vocabIds && vocabIds.length > 0) {
            // Plan C: Batch Replenishment
            log.info({ count: vocabIds.length }, 'ğŸ‘‰ ç­–ç•¥: Plan C (Batch IDs)');
            candidates = await fetchSpecificCandidates(userId, vocabIds);
        } else if (vocabId) {
            // Plan B: Single Emergency Replenishment
            log.info({ vocabId }, 'ğŸ‘‰ ç­–ç•¥: Plan B (Single ID)');
            candidates = await fetchSpecificCandidates(userId, [Number(vocabId)]);
        } else {
            // [Fix] V2 Generic Fetch (Schedule-Driven)
            if (job.name.startsWith('generate-')) {
                log.info({ mode }, 'ğŸ‘‰ ç­–ç•¥: V2 Generic Fetch (Scheduled)');
                const limit = job.data.forceLimit || 10;
                candidates = await fetchDueCandidates(userId, mode, limit);
            } else {
                log.warn({ jobName: job.name }, 'âŒ æœªçŸ¥ä»»åŠ¡ç±»å‹ï¼Œè·³è¿‡');
                return { success: false, reason: 'legacy_not_supported_v2' };
            }
        }

        if (candidates.length === 0) {
            log.warn({ correlationId }, 'âš ï¸ æ— å¯ç”¨å€™é€‰è¯ (Candidates Empty)');
            return { success: false, reason: 'no_candidates' };
        }

        log.info({ count: candidates.length }, 'âœ… é”å®šå€™é€‰è¯ (Candidates Locked)');

        // ============================================
        // 2. å‡†å¤‡ Prompt è¾“å…¥ & è°ƒç”¨ LLM
        // ============================================
        // ============================================
        // 2. å‡†å¤‡ Prompt è¾“å…¥ & è°ƒç”¨ LLM
        // ============================================

        // [Refactor] Dynamic Generator Routing
        let systemPrompt = '';
        let userPrompt = '';

        switch (mode) {
            case 'SYNTAX': {
                const { getL0SyntaxBatchPrompt } = await import('@/lib/generators/l0/syntax');
                const inputs = await Promise.all(candidates.map(c => mapToSyntaxInput(userId, c)));
                const p = getL0SyntaxBatchPrompt(inputs);
                systemPrompt = p.system;
                userPrompt = p.user;
                break;
            }
            case 'PHRASE': {
                const { getL0PhraseBatchPrompt } = await import('@/lib/generators/l0/phrase');
                // Use context words as modifiers (1+N)
                const inputs = await Promise.all(candidates.map(async c => {
                    // Fallback logic: if no collocations, search for context words
                    // But Phrase generator prefers simple modifiers.
                    // Let's use getContextWords which fetches related words.
                    const modifiers = await getContextWords(userId, c.vocabId, c.word);
                    return {
                        targetWord: c.word,
                        meaning: c.definition_cn || 'æš‚æ— é‡Šä¹‰',
                        modifiers: modifiers.length > 0 ? modifiers : ['frequently', 'highly', 'effectively'] // Generic fallback
                    };
                }));
                const p = getL0PhraseBatchPrompt(inputs);
                systemPrompt = p.system;
                userPrompt = p.user;
                break;
            }
            case 'BLITZ': {
                const { getL0BlitzBatchPrompt } = await import('@/lib/generators/l0/blitz');
                const inputs = candidates.map(c => {
                    // Extract collocations string[] from JSON
                    let collys: string[] = [];
                    if (Array.isArray(c.collocations)) {
                        collys = c.collocations.map((item: any) => typeof item === 'string' ? item : item.text).filter(Boolean);
                    }

                    return {
                        targetWord: c.word,
                        meaning: c.definition_cn || '',
                        collocations: collys
                    };
                });
                const p = getL0BlitzBatchPrompt(inputs);
                systemPrompt = p.system;
                userPrompt = p.user;
                break;
            }
            // ... Add cases for PHRASE, CHUNKING, CONTEXT, NUANCE
            default: {
                // Fallback to legacy or error
                log.warn({ mode }, 'No generator found for mode, using legacy Syntax');
                const { getL0SyntaxBatchPrompt } = await import('@/lib/generators/l0/syntax');
                const inputs = await Promise.all(candidates.map(c => mapToSyntaxInput(userId, c)));
                const p = getL0SyntaxBatchPrompt(inputs);
                systemPrompt = p.system;
                userPrompt = p.user;
            }
        }

        const { text, provider } = await generateWithFailover(systemPrompt, userPrompt);

        log.info({ correlationId, provider }, 'LLM ç”Ÿæˆå®Œæˆ');

        // ============================================
        // 3. è§£æ & éªŒè¯
        // ============================================
        let resultData;
        try {
            // [Safe Parse] ä½¿ç”¨ lib/ai/utils æä¾›çš„å®‰å…¨è§£æ
            resultData = safeParse(text, BatchDrillOutputSchema, {
                model: provider,
                systemPrompt: systemPrompt,
                userPrompt: userPrompt
            });
        } catch (e) {
            // safeParse å†…éƒ¨å·²è®°å½• logAIErrorï¼Œè¿™é‡Œåªéœ€rethrowä¸­æ–­æµç¨‹
            throw new Error('AI response parsing failed');
        }

        // ============================================
        // 4. ä¿å­˜åˆ° V2 Inventory (Redis)
        // ============================================
        const generatedDrills = resultData.drills;
        let successCount = 0;

        for (let i = 0; i < generatedDrills.length; i++) {
            const rawDrill = generatedDrills[i];
            const candidate = candidates[i];

            // Safety check: alignment
            if (!candidate) continue;

            const payload: BriefingPayload = {
                meta: {
                    format: rawDrill.meta.format as any,
                    mode: mode,
                    batch_size: 1, // Stored individually
                    sys_prompt_version: 'v2.8-schedule',
                    vocabId: candidate.vocabId,
                    target_word: candidate.word,
                    source: 'llm_v2'
                },
                segments: rawDrill.segments,
            };

            await inventory.pushDrill(userId, mode, candidate.vocabId, payload);
            successCount++;
        }

        log.info({ correlationId, successCount }, 'Drill V2 å…¥åº“å®Œæˆ');

        return { success: true, count: successCount, provider };

    } catch (error) {
        log.error({ correlationId, error: (error as Error).message }, 'Drill ç”Ÿæˆå¤±è´¥');
        throw error;
    }
}

// --- Helpers ---

interface DrillCandidate {
    vocabId: number;
    word: string;
    definition_cn: string | null;
    word_family: any;
    collocations?: any;
}

async function fetchSpecificCandidates(userId: string, vocabIds: number[]): Promise<DrillCandidate[]> {
    const vocabs = await db.vocab.findMany({
        where: { id: { in: vocabIds } }
    });

    // Maintain order same as input IDs? 
    // Not strictly necessary for batch gen, but mapToCandidate is needed.
    return vocabs.map(mapToCandidate);
}

function mapToCandidate(v: Vocab): DrillCandidate {
    return {
        vocabId: v.id,
        word: v.word,
        definition_cn: v.definition_cn,
        word_family: v.word_family,
        collocations: v.collocations,
    };
}

/**
 * è·å–ä¸Šä¸‹æ–‡å•è¯ (The "N" in "1+N")
 * ç­–ç•¥ (Hybrid):
 * 1. å°è¯•ä» UserProgress (Learning/Review) ä¸­æ‰¾è¯­ä¹‰ç›¸å…³çš„ (Vector Search)
 * 2. å¦‚æœä¸è¶³ 3 ä¸ªï¼Œä» Global Vocab ä¸­æ‰¾è¯­ä¹‰ç›¸å…³çš„ (Vector Search)
 * 3. å…œåº•ï¼šéšæœºé€‰æ‹©
 */
async function getContextWords(userId: string, targetVocabId: number, targetWord: string): Promise<string[]> {
    try {
        const selectorResult = await ContextSelector.select(userId, targetVocabId, {
            count: 3,
            strategies: ['USER_VECTOR', 'GLOBAL_VECTOR', 'RANDOM'],
            minDistance: 0.15,
            maxDistance: 0.5,
            excludeIds: [targetVocabId]
        });

        return selectorResult.map(v => v.word);
    } catch (e) {
        log.error({ error: String(e), targetWord }, 'ContextSelector failed, returning empty');
        return [];
    }
}

/**
 * è·å–éœ€è¦é¢„ç”Ÿæˆçš„å€™é€‰è¯
 * [é‡æ„] ç°åœ¨ç›´æ¥ä½¿ç”¨ OMPS é€‰è¯é€»è¾‘ï¼Œç¡®ä¿ç”Ÿäº§å’Œæ¶ˆè´¹ä½¿ç”¨ç›¸åŒçš„ç­–ç•¥
 */
async function fetchDueCandidates(userId: string, mode: SessionMode, limit: number): Promise<DrillCandidate[]> {
    // å¯¼å…¥ OMPS é€‰è¯å¼•æ“
    const { fetchOMPSCandidates } = await import('@/lib/services/omps-core');

    // é…ç½®è¯æ€§è¿‡æ»¤ï¼ˆä¸ get-next-drill.ts ä¿æŒä¸€è‡´ï¼‰
    let posFilter: string[] | undefined;
    if (mode === 'SYNTAX') {
        posFilter = ['v', 'n', 'v.', 'n.', 'vi', 'vt', 'vi.', 'vt.', 'noun', 'verb', 'åè©', 'å‹•è©'];
    }

    // 1. ä½¿ç”¨ OMPS è·å–å€™é€‰è¯ï¼ˆä¸æ¶ˆè´¹ä¾§é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
    const bufferLimit = limit * 2; // è·å–2å€æ•°é‡ï¼Œç”¨äºè¿‡æ»¤
    const ompsCandidates = await fetchOMPSCandidates(
        userId,
        bufferLimit,
        { posFilter },
        [], // excludeIds
        mode // [Fix] Pass mode to determine track
    );

    if (ompsCandidates.length === 0) {
        return [];
    }

    // 2. è¿‡æ»¤å‡ºåº“å­˜ä¸è¶³çš„å•è¯ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
    const vocabIds = ompsCandidates.map(c => c.vocabId);
    const inventoryCounts = await inventory.getInventoryCounts(userId, mode, vocabIds);

    const needsGeneration = ompsCandidates.filter(c => {
        const count = inventoryCounts[c.vocabId] || 0;
        return count < 2; // åº“å­˜ < 2 æ‰éœ€è¦ç”Ÿæˆ
    });

    if (needsGeneration.length < ompsCandidates.length) {
        log.info(
            { userId, mode, skipped: ompsCandidates.length - needsGeneration.length },
            'âœ… è·³è¿‡å·²æœ‰åº“å­˜çš„å•è¯'
        );
    }

    // 3. è½¬æ¢ä¸º DrillCandidate æ ¼å¼
    const candidates = needsGeneration.map(omps => ({
        vocabId: omps.vocabId,
        word: omps.word,
        definition_cn: omps.definition_cn,
        word_family: omps.word_family,
        collocations: omps.collocations,
    }));

    // 4. è¿”å›æŒ‡å®šæ•°é‡
    return candidates.slice(0, limit);
}

// --- Helper: Input Mappers ---

async function mapToSyntaxInput(userId: string, c: DrillCandidate) {
    const contextWords = await getContextWords(userId, c.vocabId, c.word);
    return {
        targetWord: c.word,
        meaning: c.definition_cn || 'æš‚æ— é‡Šä¹‰',
        contextWords,
        wordFamily: (c.word_family as Record<string, string>) || { v: c.word },
    };
}
