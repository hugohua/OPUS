import { redis as connection } from '@/lib/queue/connection';
import { BriefingPayload, SessionMode, DrillType } from '@/types/briefing';
import { createLogger } from '@/lib/logger';
import { inventoryQueue } from '@/lib/queue';

const log = createLogger('lib:inventory');

// Redis Key Generator
const keys = {
    /**
     * @deprecated æ—§ç‰ˆ key (æŒ‰ mode åˆ†ç»„)ï¼Œåç»­åˆ é™¤
     */
    drillList: (userId: string, mode: string, vocabId: number | string) =>
        `user:${userId}:mode:${mode}:vocab:${vocabId}:drills`,

    /**
     * [V2.0 New] æŒ‰é¢˜å‹åˆ†é¢‘é“å­˜å‚¨
     * inventory:{userId}:vocab:{vocabId}:{drillType}
     */
    drillTypeList: (userId: string, vocabId: number | string, drillType: DrillType) =>
        `inventory:${userId}:vocab:${vocabId}:${drillType}`,

    replenishBuffer: 'buffer:replenish_drills',
    stats: (userId: string) => `user:${userId}:inventory:stats`,
};

/**
 * æ ¸å¿ƒåº“å­˜æ¨¡å— (Schedule-Driven)
 * è´Ÿè´£ç®¡ç†å•è¯é¢—ç²’åº¦çš„å¼¹è¯åº“
 */
export const inventory = {
    /**
     * å°†ç”Ÿæˆçš„ Drill æ¨å…¥åº“å­˜
     */
    async pushDrill(userId: string, mode: string, vocabId: number | string, drill: BriefingPayload) {
        const key = keys.drillList(userId, mode, vocabId);

        // Multi-exec for atomicity
        const pipeline = connection.pipeline();
        pipeline.rpush(key, JSON.stringify(drill));
        pipeline.hincrby(keys.stats(userId), mode, 1);
        await pipeline.exec();

        log.info({ userId, mode, vocabId }, 'Drill pushed to inventory');
    },

    /**
     * æ¶ˆè´¹ä¸€ä¸ª Drill (åŸå­æ“ä½œ)
     * Side Effect: å¦‚æœåº“å­˜æ°´ä½ä½ (<2)ï¼Œè§¦å‘åå°è¡¥å……
     */
    async popDrill(userId: string, mode: string, vocabId: number | string): Promise<BriefingPayload | null> {
        const key = keys.drillList(userId, mode, vocabId);

        // 1. Pop content
        const results = await connection.multi()
            .lpop(key)
            .exec();

        const data = results?.[0]?.[1] as string | null;

        // If we popped something, decrement stats
        if (data) {
            await connection.hincrby(keys.stats(userId), mode, -1);
        }

        // 2. Check remaining length (Async check)
        this.checkAndTriggerReplenish(userId, mode, vocabId).catch(err => {
            log.error({ error: err.message, userId, mode, vocabId }, 'Failed to trigger replenish');
        });

        if (!data) return null;
        return JSON.parse(data);
    },

    /**
     * æ£€æŸ¥åº“å­˜æ°´ä½å¹¶è§¦å‘è¡¥å……
     */
    async checkAndTriggerReplenish(userId: string, mode: string, vocabId: number | string) {
        const key = keys.drillList(userId, mode, vocabId);
        const len = await connection.llen(key);

        if (len < 2) {
            log.info({ userId, mode, vocabId, len }, 'ğŸ“‰ Low inventory detected. Buffering for replenishment.');
            // Add to buffer for Batch Aggregation (Plan C)
            await this.addToBuffer(userId, mode, vocabId);

            // Trigger check immediately
            await this.checkBufferAndFlush();
        }
    },

    /**
     * å°† ç¼ºè´§ID åŠ å…¥ç¼“å†²åŒº
     * Format: "userId:mode:vocabId"
     */
    async addToBuffer(userId: string, mode: string, vocabId: number | string) {
        const item = `${userId}:${mode}:${vocabId}`;
        await connection.sadd(keys.replenishBuffer, item);
    },

    /**
     * æ£€æŸ¥ç¼“å†²åŒºå¹¶ Flush (å¦‚æ»¡è¶³é˜ˆå€¼)
     */
    async checkBufferAndFlush() {
        const count = await connection.scard(keys.replenishBuffer);

        // Threshold = 5
        if (count >= 5) {
            await this.flushBuffer();
        }
    },

    /**
     * å¼ºåˆ¶ Flush ç¼“å†²åŒº (ç”Ÿæˆ Batch Job)
     */
    async flushBuffer() {
        // Pop 10 items to process
        const items = await connection.spop(keys.replenishBuffer, 10);
        if (items.length === 0) return;

        // Group by User + Mode
        const groupedJobs: Record<string, number[]> = {};

        for (const item of items) {
            const parts = item.split(':');
            // item is uid:mode:vid. But mode might contain chars?
            // Safer parsing: 
            // format: userId:mode:vocabId. 
            // userId is cuid (string), mode is enum, vocabId is int.

            if (parts.length < 3) continue;

            const vocabId = parseInt(parts.pop()!);
            const mode = parts.pop()!;
            const userId = parts.join(':'); // remaining part is userId

            const jobKey = `${userId}:${mode}`;

            if (!groupedJobs[jobKey]) groupedJobs[jobKey] = [];
            groupedJobs[jobKey].push(vocabId);
        }

        // Enqueue Batch Jobs (Plan C)
        for (const [key, vids] of Object.entries(groupedJobs)) {
            const [uid, mode] = key.split(':');

            await inventoryQueue.add('replenish_batch', {
                userId: uid,
                mode: mode as SessionMode,
                vocabIds: vids,
                correlationId: `batch-replenish-${Date.now()}`
            }, {
                priority: 5 // Low priority for Plan C
            });

            log.info({ userId: uid, mode, count: vids.length }, 'ğŸ“¦ Batch replenishment job enqueued');
        }
    },

    /**
     * è§¦å‘æ€¥æ•‘ä»»åŠ¡ (Plan B)
     */
    async triggerEmergency(userId: string, mode: string, vocabId: number | string) {
        await inventoryQueue.add('replenish_one', {
            userId,
            mode: mode as SessionMode,
            vocabId: Number(vocabId),
            correlationId: `emergency-${vocabId}-${Date.now()}`
        }, {
            priority: 1 // High Priority
        });
        log.info({ userId, mode, vocabId }, 'ğŸš‘ Emergency replenishment triggered');
    },

    /**
     * è§¦å‘æ‰¹é‡æ€¥æ•‘ä»»åŠ¡ (Plan B in Batch)
     * ç”¨äºå†·å¯åŠ¨æ—¶ï¼Œä¸€æ¬¡æ€§è¡¥å……å¤šä¸ªç¼ºè´§å•è¯ï¼Œé¿å…å‘é€å¤šä¸ªå•ç‹¬çš„æ€¥æ•‘åŒ…
     */
    async triggerBatchEmergency(userId: string, mode: string, vocabIds: number[]) {
        if (vocabIds.length === 0) return;

        await inventoryQueue.add('replenish_batch', {
            userId,
            mode: mode as SessionMode,
            vocabIds,
            correlationId: `batch-emergency-${Date.now()}`
        }, {
            priority: 1 // High Priority (Same as Emergency)
        });
        log.info({ userId, mode, count: vocabIds.length }, 'ğŸš‘ğŸ“¦ Batch Emergency replenishment triggered');
    },

    /**
     * è·å–åº“å­˜ç»Ÿè®¡
     */
    async getInventoryStats(userId: string) {
        const raw = await connection.hgetall(keys.stats(userId));

        // Convert string values to numbers
        return {
            SYNTAX: parseInt(raw.SYNTAX || '0'),
            CHUNKING: parseInt(raw.CHUNKING || '0'),
            NUANCE: parseInt(raw.NUANCE || '0'),
            BLITZ: parseInt(raw.BLITZ || '0'),
            total: Object.values(raw).reduce((a: number, b: string) => a + (parseInt(b) || 0), 0)
        };
    },
    /**
     * getInventoryCounts
     * æ‰¹é‡è·å–æŒ‡å®šå•è¯çš„åº“å­˜æ•°é‡
     */
    async getInventoryCounts(userId: string, mode: string, vocabIds: number[]): Promise<Record<number, number>> {
        if (vocabIds.length === 0) return {};

        const pipeline = connection.pipeline();
        vocabIds.forEach((vid) => {
            pipeline.llen(keys.drillList(userId, mode, vid));
        });

        const results = await pipeline.exec();
        const counts: Record<number, number> = {};

        vocabIds.forEach((vid, index) => {
            const result = results?.[index];
            // result is [error, result]
            const count = result && result[0] === null ? (result[1] as number) : 0;
            counts[vid] = count;
        });

        return counts;
    },

    // ============================================
    // [V2.0 New] åˆ†é¢‘é“é¢˜å‹åº“å­˜ API
    // ============================================

    /**
     * [V2.0] æ¨å…¥æŒ‡å®šé¢˜å‹çš„ Drill
     */
    async pushDrillV2(userId: string, vocabId: number, drillType: DrillType, drill: BriefingPayload) {
        const key = keys.drillTypeList(userId, vocabId, drillType);
        await connection.rpush(key, JSON.stringify(drill));
        log.info({ userId, vocabId, drillType }, '[V2] Drill pushed to inventory');
    },

    /**
     * [V2.0] æ¶ˆè´¹æŒ‡å®šé¢˜å‹çš„ Drill
     */
    async popDrillV2(userId: string, vocabId: number, drillType: DrillType): Promise<BriefingPayload | null> {
        const key = keys.drillTypeList(userId, vocabId, drillType);
        const data = await connection.lpop(key);
        if (!data) return null;
        return JSON.parse(data);
    },

    /**
     * [V2.0] è·å–å•è¯æ‰€æœ‰é¢˜å‹çš„åº“å­˜æ•°é‡
     */
    async getInventoryCountsByType(userId: string, vocabId: number): Promise<Record<DrillType, number>> {
        const drillTypes: DrillType[] = ['S_V_O', 'VISUAL_TRAP', 'PART5_CLOZE'];
        const pipeline = connection.pipeline();

        drillTypes.forEach((dt) => {
            pipeline.llen(keys.drillTypeList(userId, vocabId, dt));
        });

        const results = await pipeline.exec();
        const counts: Partial<Record<DrillType, number>> = {};

        drillTypes.forEach((dt, index) => {
            const result = results?.[index];
            counts[dt] = result && result[0] === null ? (result[1] as number) : 0;
        });

        return counts as Record<DrillType, number>;
    },

    /**
     * [V2.0] æ‰¹é‡è·å–å¤šä¸ªå•è¯çš„æŒ‡å®šé¢˜å‹åº“å­˜
     */
    async getInventoryCountsByTypeV2(
        userId: string,
        vocabIds: number[],
        drillType: DrillType
    ): Promise<Record<number, number>> {
        if (vocabIds.length === 0) return {};

        const pipeline = connection.pipeline();
        vocabIds.forEach((vid) => {
            pipeline.llen(keys.drillTypeList(userId, vid, drillType));
        });

        const results = await pipeline.exec();
        const counts: Record<number, number> = {};

        vocabIds.forEach((vid, index) => {
            const result = results?.[index];
            counts[vid] = result && result[0] === null ? (result[1] as number) : 0;
        });

        return counts;
    }
};
